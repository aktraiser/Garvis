// Test PDF avec normalisation Unicode activÃ©e
// Teste la nouvelle fonctionnalitÃ© de normalisation des ligatures

use std::path::PathBuf;
use tokio::fs;
use tracing::info;
use gravis_app_lib::rag::ocr::{
    SimplePdfExtractor, PdfExtractConfig, 
    normalize_for_rag, needs_normalization
};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Initialiser le logging
    tracing_subscriber::fmt()
        .with_max_level(tracing::Level::INFO)
        .init();

    info!("ğŸš€ Test PDF avec Normalisation Unicode");

    // Chemin vers le PDF DeepSeek-OCR
    let pdf_path = PathBuf::from("/Users/lucasbometon/Desktop/voice_flow/gravis/gravis-app/2510.18234v1.pdf");
    
    if !pdf_path.exists() {
        return Err("PDF file not found".into());
    }

    info!("ğŸ“„ PDF trouvÃ©: {:?}", pdf_path);

    // CrÃ©er rÃ©pertoire de sortie
    let output_dir = PathBuf::from("/Users/lucasbometon/Desktop/voice_flow/gravis/gravis-app/pdf_normalized_results");
    if !output_dir.exists() {
        fs::create_dir_all(&output_dir).await?;
    }

    // Test 1: Extraction SANS normalisation
    info!("ğŸ“– Test 1: Extraction SANS normalisation Unicode");
    let config_raw = PdfExtractConfig {
        min_tokens: 10,
        timeout: std::time::Duration::from_secs(30),
        normalize_unicode: false,  // DÃ©sactivÃ©e
    };
    
    let extractor_raw = SimplePdfExtractor::new(config_raw);
    let result_raw = extractor_raw.extract_pdf_text(&pdf_path).await?;
    
    info!("âœ… Extraction brute rÃ©ussie:");
    info!("   ğŸ“ {} caractÃ¨res", result_raw.text.len());
    info!("   ğŸ”¤ {} mots", result_raw.text.split_whitespace().count());
    
    // Sauvegarder le texte brut
    let raw_file = output_dir.join("raw_extract_result.txt");
    fs::write(&raw_file, &result_raw.text).await?;
    info!("   ğŸ’¾ SauvegardÃ©: {:?}", raw_file);

    // Test 2: Extraction AVEC normalisation
    info!("ğŸ“– Test 2: Extraction AVEC normalisation Unicode");
    let config_normalized = PdfExtractConfig {
        min_tokens: 10,
        timeout: std::time::Duration::from_secs(30),
        normalize_unicode: true,  // ActivÃ©e
    };
    
    let extractor_normalized = SimplePdfExtractor::new(config_normalized);
    let result_normalized = extractor_normalized.extract_pdf_text(&pdf_path).await?;
    
    info!("âœ… Extraction normalisÃ©e rÃ©ussie:");
    info!("   ğŸ“ {} caractÃ¨res", result_normalized.text.len());
    info!("   ğŸ”¤ {} mots", result_normalized.text.split_whitespace().count());
    
    // Sauvegarder le texte normalisÃ©
    let normalized_file = output_dir.join("normalized_extract_result.txt");
    fs::write(&normalized_file, &result_normalized.text).await?;
    info!("   ğŸ’¾ SauvegardÃ©: {:?}", normalized_file);

    // Test 3: Comparaison et dÃ©tection de problÃ¨mes
    info!("ğŸ“Š Test 3: Analyse comparative");
    
    let needs_norm = needs_normalization(&result_raw.text);
    info!("ğŸ” DÃ©tection automatique: normalisation {} nÃ©cessaire", 
          if needs_norm { "EST" } else { "N'EST PAS" });
    
    // Compter les ligatures dans le texte brut
    let ligature_count = result_raw.text.chars()
        .filter(|&c| matches!(c, 'ï¬' | 'ï¬‚' | 'ï¬€' | 'ï¬ƒ' | 'ï¬„'))
        .count();
    
    info!("ğŸ“ˆ Statistiques:");
    info!("   ğŸ”¤ Ligatures dÃ©tectÃ©es dans le brut: {}", ligature_count);
    info!("   ğŸ“ DiffÃ©rence de taille: {} chars", 
          result_normalized.text.len() as i32 - result_raw.text.len() as i32);
    
    // Test 4: Normalisation manuelle pour vÃ©rification
    info!("ğŸ§ª Test 4: Normalisation manuelle");
    let manual_normalized = normalize_for_rag(&result_raw.text);
    let manual_matches = manual_normalized == result_normalized.text;
    
    info!("ğŸ”¬ VÃ©rification cohÃ©rence: {}", 
          if manual_matches { "âœ… CONFORME" } else { "âŒ DIFFÃ‰RENCE DÃ‰TECTÃ‰E" });
    
    if !manual_matches {
        let diff_len = manual_normalized.len() as i32 - result_normalized.text.len() as i32;
        info!("   ğŸ“ DiffÃ©rence taille manuelle vs pipeline: {} chars", diff_len);
    }

    // Test 5: Recherche d'exemples de normalisation
    info!("ğŸ” Test 5: Exemples de normalisation trouvÃ©s");
    
    let examples = find_normalization_examples(&result_raw.text, &result_normalized.text);
    if examples.is_empty() {
        info!("   â„¹ï¸ Aucun exemple de normalisation trouvÃ©");
    } else {
        info!("   ğŸ¯ {} exemples trouvÃ©s:", examples.len().min(5));
        for (i, (before, after)) in examples.iter().take(5).enumerate() {
            info!("   {}. '{}' â†’ '{}'", i + 1, before, after);
        }
    }

    // Sauvegarder un rapport de comparaison
    let report = format!(
        "# Rapport de Normalisation Unicode - GRAVIS OCR\n\n\
        ## Statistiques\n\
        - Texte brut: {} caractÃ¨res, {} mots\n\
        - Texte normalisÃ©: {} caractÃ¨res, {} mots\n\
        - Ligatures dÃ©tectÃ©es: {}\n\
        - Normalisation nÃ©cessaire: {}\n\
        - CohÃ©rence pipeline: {}\n\n\
        ## Exemples de normalisation\n{}\n",
        result_raw.text.len(),
        result_raw.text.split_whitespace().count(),
        result_normalized.text.len(),
        result_normalized.text.split_whitespace().count(),
        ligature_count,
        if needs_norm { "Oui" } else { "Non" },
        if manual_matches { "âœ… OK" } else { "âŒ ProblÃ¨me" },
        examples.iter()
            .take(10)
            .map(|(before, after)| format!("- '{}' â†’ '{}'", before, after))
            .collect::<Vec<_>>()
            .join("\n")
    );
    
    let report_file = output_dir.join("normalization_report.md");
    fs::write(&report_file, &report).await?;
    info!("ğŸ“Š Rapport sauvegardÃ©: {:?}", report_file);

    info!("ğŸ“ Tous les rÃ©sultats sauvegardÃ©s dans: {:?}", output_dir);
    info!("âœ… Test de normalisation Unicode terminÃ© !");

    Ok(())
}

/// Trouve des exemples concrets de normalisation
fn find_normalization_examples(before: &str, after: &str) -> Vec<(String, String)> {
    let mut examples = Vec::new();
    
    // Diviser en mots pour comparaison
    let words_before: Vec<&str> = before.split_whitespace().collect();
    let words_after: Vec<&str> = after.split_whitespace().collect();
    
    // Comparer mot par mot (approximatif)
    for (word_before, word_after) in words_before.iter().zip(words_after.iter()) {
        if word_before != word_after && word_before.len() > 2 && word_after.len() > 2 {
            // VÃ©rifier si c'est vraiment une normalisation (pas juste une diffÃ©rence)
            if word_before.chars().any(|c| matches!(c, 'ï¬' | 'ï¬‚' | 'ï¬€' | 'ï¬ƒ' | 'ï¬„')) {
                examples.push((word_before.to_string(), word_after.to_string()));
            }
        }
    }
    
    examples
}